{
  "config": {
    "db": "medrag",
    "table": "chunks",
    "k": 10,
    "embed_model": "BAAI/bge-small-en-v1.5",
    "probes_tested": [
      1,
      4,
      8,
      16,
      32
    ],
    "n_queries": 10
  },
  "baseline_seqscan": {
    "latency": {
      "n": 10,
      "mean_ms": 9.755491744726896,
      "median_ms": 8.735916577279568,
      "p95_ms": 14.744664845056825
    }
  },
  "ivfflat": {
    "1": {
      "latency": {
        "n": 10,
        "mean_ms": 8.093745773658156,
        "median_ms": 8.034582948312163,
        "p95_ms": 8.351368876174092
      },
      "recall_at_k_mean": 1.0,
      "recall_at_k_median": 1.0,
      "recall_at_k_p5": 1.0,
      "recall_at_k_p95": 1.0
    },
    "4": {
      "latency": {
        "n": 10,
        "mean_ms": 8.286824962124228,
        "median_ms": 8.08149971999228,
        "p95_ms": 8.92106059473008
      },
      "recall_at_k_mean": 1.0,
      "recall_at_k_median": 1.0,
      "recall_at_k_p5": 1.0,
      "recall_at_k_p95": 1.0
    },
    "8": {
      "latency": {
        "n": 10,
        "mean_ms": 8.104195958003402,
        "median_ms": 8.080104133114219,
        "p95_ms": 8.255237597040832
      },
      "recall_at_k_mean": 1.0,
      "recall_at_k_median": 1.0,
      "recall_at_k_p5": 1.0,
      "recall_at_k_p95": 1.0
    },
    "16": {
      "latency": {
        "n": 10,
        "mean_ms": 8.051566546782851,
        "median_ms": 8.02824948914349,
        "p95_ms": 8.170643565244973
      },
      "recall_at_k_mean": 1.0,
      "recall_at_k_median": 1.0,
      "recall_at_k_p5": 1.0,
      "recall_at_k_p95": 1.0
    },
    "32": {
      "latency": {
        "n": 10,
        "mean_ms": 8.220591582357883,
        "median_ms": 8.103853790089488,
        "p95_ms": 8.754220977425575
      },
      "recall_at_k_mean": 1.0,
      "recall_at_k_median": 1.0,
      "recall_at_k_p5": 1.0,
      "recall_at_k_p95": 1.0
    }
  }
}

Tip: capture this JSON and plot a probes vs. latency/recall chart in your README.
